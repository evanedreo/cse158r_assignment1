ASSIGNMENT 1 - BOOK RECOMMENDATION SYSTEMS
==========================================

Student: Evan Edreo Honggo Widjojo
Date: November 17, 2025

TASK 1: RATING PREDICTION
--------------------------
Approach:
I implemented a bias-based collaborative filtering model that predicts ratings using:
1. Global average rating as the baseline (3.687)
2. User bias: Each user's average deviation from the global mean
3. Item bias: Each book's average deviation from the global mean

The final prediction formula is:
    prediction = global_average + user_bias + item_bias

Predictions are clipped to the valid rating range [0, 5].

This approach significantly improves upon the baseline by capturing both user tendencies 
(some users rate higher/lower on average) and item quality (some books are universally 
better/worse rated). The model is simple but effective for this task.

Expected improvement: This should reduce MSE significantly compared to the baseline which 
only uses user averages without considering item-specific biases.


TASK 2: READ PREDICTION
------------------------
Approach:
I implemented a hybrid approach combining popularity-based and user-specific signals:

1. Popularity baseline: Books accounting for the top 50% of interactions are marked as 
   likely to be read
2. Book exposure threshold: Books read at least 5 times in training data are considered 
   more likely to be read
3. User history tracking: For users we've seen before, we track which books they've 
   interacted with

The model predicts "1" (will read) if:
- The book is in the popular set (top 50% of interactions), OR
- The book has been read at least 5 times in training data

This improves upon the baseline by better handling the boundary cases and using a more 
refined popularity threshold.

Expected improvement: Should achieve better accuracy than the baseline by using a more 
nuanced popularity measure.


TASK 3: CATEGORY PREDICTION
---------------------------
Approach:
I implemented a multi-feature text classification system using:

1. TF-IDF scoring: Calculated term frequency-inverse document frequency scores for words 
   in each category to identify discriminative terms

2. Keyword features: Hand-crafted keyword lists for each category:
   - Children: "children", "child", "kid", "picture", etc.
   - Comics/Graphic: "comic", "graphic", "manga", "panel", etc.
   - Fantasy/Paranormal: "fantasy", "magic", "dragon", "vampire", etc.
   - Mystery/Thriller: "mystery", "thriller", "crime", "detective", etc.
   - Young Adult: "love", "romance", "teen", "high school", etc.

3. Category priors: Log probability based on training set distribution

4. Rating signal: Weak signal using rating patterns (some genres tend to have different 
   rating distributions)

The model scores each category using a weighted combination of these features and predicts 
the category with the highest score. Keywords receive strong weights (5-10x) when matched, 
and TF-IDF scores provide additional discrimination.

Expected improvement: The combination of hand-crafted features and statistical word 
importance should significantly outperform the baseline's simple keyword matching, 
especially for ambiguous reviews.


IMPLEMENTATION NOTES
-------------------
- All code is in assignment1.py
- The script processes data sequentially: ratings, then read prediction, then categories
- Training data statistics:
  * 200,000 interaction records
  * 27,945 unique users
  * 6,688 unique books
  * 100,000 category training reviews
- No external libraries beyond standard Python (gzip, collections, math, string)
- Predictions are formatted according to the required CSV structure


POTENTIAL IMPROVEMENTS
----------------------
If more time/resources were available:
1. Rating prediction: Implement matrix factorization (SVD/ALS) for latent factor models
2. Read prediction: Use collaborative filtering with user-user or item-item similarity
3. Category prediction: Use proper ML classifiers (sklearn LogisticRegression, SVM, or 
   neural networks) with better text preprocessing and n-gram features

